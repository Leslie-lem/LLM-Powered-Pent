package ai.pentest;

import burp.*;

import ai.pentest.ui.LLMLivePanel;
import javax.swing.*;
import java.util.ArrayList;
import java.util.List;
import java.util.Collections;
import java.util.Comparator;
import java.util.stream.Collectors;
import java.util.HashMap;
import java.util.Map;

/**
 * Burp Suite extension entry point implementing:
 * - IBurpExtender
 * - IProxyListener (capture/history)
 * - IContextMenuFactory (actions for LLM and safe active checks)
 *
 * Safe by default (passive-only) until user enables active checks in UI.
 */
public class AIPentestExtender implements IBurpExtender, IExtensionStateListener, IProxyListener, IContextMenuFactory {

    private IBurpExtenderCallbacks callbacks;
    private IExtensionHelpers helpers;

    private SettingsPanel settingsPanel;
    private LLMLivePanel livePanel;
    private RequestCache requestCache;
    private PromptBuilder promptBuilder;
    private LLMClient llmClient;

    private AuditLogger auditLogger;
    private LLMOutputLogger llmOutputLogger;
    private LLMPromptLogger llmPromptLogger;
    private PIIMasker piiMasker;
    private ActiveChecks activeChecks;
    private ai.pentest.ptt.PTTExecutor pttExecutor;
    private ai.pentest.ptt.PTTCache pttCache;
    private EndpointBatchManager batchManager;
    private MemoryManager memoryManager;
    private MemoryPanel memoryPanel;
    private boolean supportsScanIssues = true;

    @Override
    public void registerExtenderCallbacks(IBurpExtenderCallbacks callbacks) {
        this.callbacks = callbacks;
        this.helpers = callbacks.getHelpers();

        callbacks.setExtensionName("AI Pentest Assistant (API)");
        callbacks.registerExtensionStateListener(this);
        callbacks.registerProxyListener(this);
        callbacks.registerContextMenuFactory(this);

        String[] burpVersionInfo = callbacks.getBurpVersion();
        String burpEdition = (burpVersionInfo != null && burpVersionInfo.length > 0)
                ? burpVersionInfo[0]
                : "";
        if (burpEdition.toLowerCase(java.util.Locale.ROOT).contains("community")) {
            supportsScanIssues = false;
            callbacks.printOutput("AI Pentest: Running on Burp Suite Community Edition. Findings will be logged but not added to the Scanner tab.");
        }

        this.auditLogger = new AuditLogger(callbacks);
        this.llmOutputLogger = new LLMOutputLogger(callbacks);
        this.llmPromptLogger = new LLMPromptLogger(callbacks);
        this.piiMasker = new PIIMasker();
        this.requestCache = new RequestCache();
        this.promptBuilder = new PromptBuilder();
        this.llmClient = new LLMClient(callbacks, auditLogger);
        this.activeChecks = new ActiveChecks(callbacks, auditLogger, this::reportTentativeIssue);
        this.pttExecutor = new ai.pentest.ptt.PTTExecutor(callbacks, 18);
        this.pttCache = new ai.pentest.ptt.PTTCache();
        this.batchManager = new EndpointBatchManager(helpers);
        
        // Initialize memory manager
        this.memoryManager = new MemoryManager();
        this.memoryManager.setRequestCache(requestCache);
        this.memoryManager.setPTTCache(pttCache);
        this.memoryManager.setLLMClient(llmClient);
        this.memoryManager.setBatchManager(batchManager);
        this.memoryManager.setAuditLogger(auditLogger);
        
        // Set up batch listener for hybrid output
        batchManager.setBatchListener(this::processBatch);

        SwingUtilities.invokeLater(() -> {
            callbacks.printOutput("AI Pentest: starting UI initialization...");
            try {
                String savedKey = callbacks.loadExtensionSetting("api_key");
                String savedModel = callbacks.loadExtensionSetting("model");
                String savedThreshold = callbacks.loadExtensionSetting("scoring_threshold");
                if (savedKey != null) llmClient.setApiKey(savedKey);
                if (savedModel != null) llmClient.setModel(savedModel);
                if (savedThreshold != null) {
                    try {
                        double threshold = Double.parseDouble(savedThreshold);
                        batchManager.setScoringThreshold(threshold);
                    } catch (NumberFormatException ignored) {}
                }
                callbacks.printOutput("AI Pentest: creating SettingsPanel");
                settingsPanel = new SettingsPanel(
                        apiKey -> llmClient.setApiKey(apiKey),
                        active -> activeChecks.setActiveChecksEnabled(active),
                        model -> llmClient.setModel(model),
                        (key, model) -> {
                            callbacks.saveExtensionSetting("api_key", key);
                            callbacks.saveExtensionSetting("model", model);
                        },
                        threshold -> {
                            batchManager.setScoringThreshold(threshold);
                            callbacks.saveExtensionSetting("scoring_threshold", String.valueOf(threshold));
                        },
                        () -> llmClient.ping()
                );
                callbacks.printOutput("AI Pentest: SettingsPanel created");
                settingsPanel.setSavedApiKey(savedKey);
                callbacks.addSuiteTab(settingsPanel);
                callbacks.printOutput("AI Pentest: Settings tab registered");
                livePanel = settingsPanel.getLivePanel();
                if (livePanel != null) {
                    livePanel.append("AI Pentest Assistant initialized. Waiting for proxy traffic...", "info");
                }
                
                callbacks.printOutput("AI Pentest: creating MemoryPanel");
                memoryPanel = new MemoryPanel(memoryManager);
                callbacks.addSuiteTab(memoryPanel);
                callbacks.printOutput("AI Pentest: Memory tab registered");
            } catch (Throwable t) {
                callbacks.printError("AI Pentest UI init failed: " + t.getMessage());
                for (StackTraceElement ste : t.getStackTrace()) {
                    callbacks.printError("    at " + ste.toString());
                }
            }
        });

        callbacks.printOutput("AI Pentest Assistant initialized. Passive-only by default.");
    }

    private void logToLivePanel(String message, String style) {
        if (livePanel == null) return;
        SwingUtilities.invokeLater(() -> livePanel.append(message, style));
    }

    @Override
    public void extensionUnloaded() {
        if (auditLogger != null) {
            auditLogger.flush();
        }
        if (llmOutputLogger != null) {
            llmOutputLogger.shutdown();
        }
        if (llmPromptLogger != null) {
            llmPromptLogger.shutdown();
        }
        if (batchManager != null) {
            batchManager.shutdown();
        }
        if (livePanel != null) {
            livePanel.append("Extension unloaded.", "info");
        }
    }

    // Proxy listener: capture traffic, fingerprint and deduplicate, skip static assets, create PTT prompts
    @Override
    public void processProxyMessage(boolean messageIsRequest, IInterceptedProxyMessage message) {
        try {
            if (!messageIsRequest) {
                return; // Only process requests for PTT
            }

            IHttpRequestResponse messageInfo = message.getMessageInfo();
            IRequestInfo requestInfo = helpers.analyzeRequest(messageInfo);

            // Skip static assets early
            if (RequestFingerprint.isLikelyStaticAsset(requestInfo)) {
                return;
            }

            String fingerprint = RequestFingerprint.buildFingerprint(helpers, messageInfo);
            if (!requestCache.shouldProcess(fingerprint)) {
                return; // dedupe
            }

			// Fetch recent samples for passive scoring (last 50 from siteMap, filter to base host/path)
			String endpointKey = requestInfo.getUrl().getHost() + requestInfo.getUrl().getPath();
			List<IHttpRequestResponse> samples = new ArrayList<>();
			try {
				IHttpRequestResponse[] siteMap = callbacks.getSiteMap("Proxy");
				for (IHttpRequestResponse sm : siteMap) {
					IRequestInfo smInfo = helpers.analyzeRequest(sm);
					if (smInfo.getUrl().getHost().equals(requestInfo.getUrl().getHost()) &&
						smInfo.getUrl().getPath().startsWith(requestInfo.getUrl().getPath().substring(0, Math.min(10, requestInfo.getUrl().getPath().length()))) &&
						samples.size() < 50) {
						samples.add(sm);
					}
				}
			} catch (Exception e) {
				callbacks.printError("SiteMap fetch failed: " + e.getMessage());
                logToLivePanel("SiteMap fetch failed: " + e.getMessage(), "error");
				samples = Collections.singletonList(messageInfo); // Fallback to current
			}

			// Build selective roots via Executor (prune irrelevant cats)
			List<ai.pentest.ptt.PTTNode> roots = pttExecutor.seedTreeForEndpoint(requestInfo);
			if (roots.isEmpty()) return; // Skip noise

			// Eval tree passively
			ai.pentest.ptt.PTTExecutor.Result res = pttExecutor.evaluatePassively(samples, roots);

			// Merge prior cache (avoid recompute)
			// Include all cached nodes, not just high-confidence (user wants all evidence)
			String cachedSnap = pttCache.getSnapshot(endpointKey);
			if (cachedSnap != null) {
				List<ai.pentest.ptt.PTTNode> priors = pttCache.loadSnapshot(cachedSnap);
				for (ai.pentest.ptt.PTTNode prior : priors) {
					// Merge all prior nodes, regardless of score (user wants all evidence)
					boolean merged = false;
					for (ai.pentest.ptt.PTTNode eval : res.evaluated) {
						if (eval.getTitle().equals(prior.getTitle())) {
							eval.setScore(Math.max(eval.getScore(), prior.getScore()));
							merged = true;
							break;
						}
					}
					if (!merged) res.evaluated.add(prior);
				}
			}
			pttCache.putSnapshot(endpointKey, res.evaluated);

			// HYBRID OUTPUT STRATEGY:
			// 1. Real-time: Show immediate indicators for high-confidence findings (non-blocking)
			// 2. Batch: Queue endpoints for batch analysis (5 related endpoints per batch)
			// Tradeoff: Real-time gives immediate feedback but may cause UI lag if too frequent.
			// Batch summaries are more efficient and coherent but delay feedback.
			// Hybrid balances both: early indicators + comprehensive batch analysis.
			
			double threshold = batchManager.getScoringThreshold();
			
			// Real-time indicator: Show high-confidence findings immediately (non-blocking)
			List<ai.pentest.ptt.PTTNode> highConf = res.evaluated.stream()
				.filter(n -> n.getScore() >= threshold)
				.sorted(Comparator.comparingDouble(ai.pentest.ptt.PTTNode::getScore).reversed())
				.limit(3)
				.collect(Collectors.toList());
			
            if (!highConf.isEmpty()) {
				// Show real-time indicator (async, non-blocking)
                String realTimePrompt = buildRealTimePrompt(requestInfo, messageInfo, highConf);
                if (llmPromptLogger != null) {
                    llmPromptLogger.logPrompt("Real-time analysis", requestInfo.getMethod(),
                            requestInfo.getUrl().getPath(), realTimePrompt);
                }
                llmClient.completeAsync(
                    realTimePrompt,
					400
				).thenAccept(response -> {
					// Execute UI updates on EDT thread
					SwingUtilities.invokeLater(() -> {
						if (response != null) {
							String maskedResponse = piiMasker.mask(response);
							callbacks.printOutput("AI Pentest [Real-time]: " + 
								requestInfo.getUrl().getPath() + " - " + 
								maskedResponse.substring(0, Math.min(200, maskedResponse.length())));
                            logToLivePanel("[Real-time] " + requestInfo.getMethod() + " " + requestInfo.getUrl().getPath() + " → " + maskedResponse,
                                    "realtime");
                            // Log to file
                            if (llmOutputLogger != null) {
                                llmOutputLogger.logRealTimeResponse(
                                    requestInfo.getMethod(),
                                    requestInfo.getUrl().getPath(),
                                    maskedResponse
                                );
                            }
						}
					});
				}).exceptionally(ex -> {
					// Handle errors and display feedback
					SwingUtilities.invokeLater(() -> {
						callbacks.printError("AI Pentest [Real-time] error: " + ex.getMessage());
                            logToLivePanel("[Real-time Error] " + ex.getMessage(), "error");
                            // Log error to file
                            if (llmOutputLogger != null) {
                                llmOutputLogger.logError("Real-time Response", ex.getMessage());
                            }
					});
					return null;
				});
			}
			
			// Queue endpoint for batch analysis (includes ALL evidence, even low scores)
			// Log individual request being analyzed
			String method = requestInfo.getMethod();
			String path = requestInfo.getUrl().getPath();
			String vulnCategory = inferVulnerabilityCategory(requestInfo, res.evaluated);
			int pttNodeCount = res.evaluated != null ? res.evaluated.size() : 0;
			
			boolean queued = batchManager.queueEndpoint(messageInfo, requestInfo, endpointKey, 
			                                           fingerprint, res.evaluated);
			if (queued) {
				// Log individual request being queued (thread-safe, printOutput is safe from any thread)
				callbacks.printOutput(String.format(
					"AI Pentest [Queued] %s %s → Category: %s | PTT Nodes: %d | Queue Position: %d",
					method, path, vulnCategory, pttNodeCount, batchManager.getPendingCount()
				));
                logToLivePanel(String.format("[Queued] %s %s → %s (nodes=%d, queue=%d)",
                        method, path, vulnCategory, pttNodeCount, batchManager.getPendingCount()), "queued");
			} else {
				callbacks.printOutput("AI Pentest: Session limit reached. Reset session to analyze more endpoints.");
                logToLivePanel("[Queued] Session limit reached. Reset session to analyze more endpoints.", "error");
			}
        } catch (Exception e) {
            callbacks.printError("Error in processProxyMessage: " + e.getMessage());
            logToLivePanel("[Proxy Error] " + e.getMessage(), "error");
        }
    }

    // Context menu actions to send to LLM or trigger safe active checks
    @Override
    public List<JMenuItem> createMenuItems(IContextMenuInvocation invocation) {
        List<JMenuItem> items = new ArrayList<>();

        JMenuItem sendToLLM = new JMenuItem("AI Pentest: Analyze with LLM (passive)");
        sendToLLM.addActionListener(evt -> handleAnalyzeWithLLM(invocation));
        items.add(sendToLLM);

        JMenuItem runActive = new JMenuItem("AI Pentest: Run Safe Active Checks...");
        runActive.addActionListener(evt -> handleRunActiveChecks(invocation));
        items.add(runActive);

        return items;
    }

    private void handleAnalyzeWithLLM(IContextMenuInvocation invocation) {
        IHttpRequestResponse[] selected = invocation.getSelectedMessages();
        if (selected == null || selected.length == 0) return;
        if (!llmClient.hasApiKey()) {
            callbacks.printOutput("AI Pentest: No API key set. Open settings tab.");
            logToLivePanel("[Manual] Analysis skipped: API key not set.", "error");
            return;
        }

        for (IHttpRequestResponse msg : selected) {
            IRequestInfo reqInfo = helpers.analyzeRequest(msg);
            if (RequestFingerprint.isLikelyStaticAsset(reqInfo)) continue;

            String summary = RequestFingerprint.buildCompactSummary(helpers, msg);
            PromptBuilder.PTTNode node = promptBuilder.buildPTTNode(reqInfo, summary);
            String prompt = promptBuilder.buildPassivePrompt(node);
            String maskedPrompt = piiMasker.mask(prompt);
            if (llmPromptLogger != null) {
                llmPromptLogger.logPrompt("Manual passive analysis", reqInfo.getMethod(), reqInfo.getUrl().getPath(), maskedPrompt);
            }
            String response = llmClient.completeWithCache(maskedPrompt, 600);

            if (response != null) {
                String maskedResponse = piiMasker.mask(response);
                callbacks.printOutput("AI Pentest (manual):\n" + maskedResponse);
                logToLivePanel("[Manual Response] " + maskedResponse, "llm");
                auditLogger.logEvent("manual_ptt", node.urlPath, maskedPrompt, maskedResponse);
            }
        }
    }

    private void handleRunActiveChecks(IContextMenuInvocation invocation) {
        IHttpRequestResponse[] selected = invocation.getSelectedMessages();
        if (selected == null || selected.length == 0) return;

        if (!activeChecks.isActiveChecksEnabled()) {
            JOptionPane.showMessageDialog(null,
                    "Active checks are disabled. Enable them in the extension settings.",
                    "AI Pentest", JOptionPane.INFORMATION_MESSAGE);
            return;
        }

        int confirm = JOptionPane.showConfirmDialog(null,
                "Run safe, non-intrusive active checks on selected requests?\n" +
                        "Only test targets you are authorized to assess.",
                "AI Pentest - Confirm", JOptionPane.OK_CANCEL_OPTION);
        if (confirm != JOptionPane.OK_OPTION) return;

        for (IHttpRequestResponse msg : selected) {
            try {
                activeChecks.runConservativeChecks(msg);
                logToLivePanel("[Active Check] Completed conservative checks for selected request.", "info");
            } catch (Exception e) {
                callbacks.printError("Active check error: " + e.getMessage());
                logToLivePanel("[Active Check Error] " + e.getMessage(), "error");
            }
        }
    }
    
    /**
     * Infer vulnerability category from request and PTT nodes (same logic as EndpointBatchManager).
     * Used for logging purposes.
     */
    private String inferVulnerabilityCategory(IRequestInfo req, List<ai.pentest.ptt.PTTNode> nodes) {
        if (nodes == null || nodes.isEmpty()) {
            return inferFromPath(req);
        }
        
        Map<String, Double> categoryScores = new HashMap<>();
        for (ai.pentest.ptt.PTTNode node : nodes) {
            String title = node.getTitle();
            double score = node.getScore();
            
            if (title.contains("BOLA")) {
                categoryScores.put("BOLA", Math.max(categoryScores.getOrDefault("BOLA", 0.0), score));
            } else if (title.contains("Broken Authentication")) {
                categoryScores.put("BrokenAuth", Math.max(categoryScores.getOrDefault("BrokenAuth", 0.0), score));
            } else if (title.contains("Security Misconfiguration")) {
                categoryScores.put("SecurityMisconfig", Math.max(categoryScores.getOrDefault("SecurityMisconfig", 0.0), score));
            } else if (title.contains("SSRF")) {
                categoryScores.put("SSRF", Math.max(categoryScores.getOrDefault("SSRF", 0.0), score));
            } else if (title.contains("Excessive Data Exposure")) {
                categoryScores.put("ExcessiveData", Math.max(categoryScores.getOrDefault("ExcessiveData", 0.0), score));
            }
        }
        
        if (!categoryScores.isEmpty()) {
            return categoryScores.entrySet().stream()
                .max(Map.Entry.comparingByValue())
                .map(Map.Entry::getKey)
                .orElse("General");
        }
        
        return inferFromPath(req);
    }
    
    private String inferFromPath(IRequestInfo req) {
        String path = req.getUrl().getPath().toLowerCase();
        if (path.contains("/user") || path.contains("/account") || path.matches(".*/\\d+.*")) {
            return "BOLA";
        } else if (path.contains("/login") || path.contains("/auth")) {
            return "BrokenAuth";
        } else if (path.contains("/admin")) {
            return "FunctionLevelAuth";
        } else if (path.contains("?url=") || path.contains("callback=")) {
            return "SSRF";
        }
        return "General";
    }
    
    /**
     * Build prompt for real-time indicator (lightweight, non-blocking).
     */
    private String buildRealTimePrompt(IRequestInfo requestInfo, IHttpRequestResponse messageInfo,
                                      List<ai.pentest.ptt.PTTNode> highConf) {
        PromptBuilder.PTTNode node = promptBuilder.buildPTTNode(requestInfo, 
            RequestFingerprint.buildCompactSummary(helpers, messageInfo));
        String prompt = promptBuilder.buildPassivePrompt(node, highConf);
        return piiMasker.maskWithPath(prompt, requestInfo.getUrl().getPath());
    }
    
    /**
     * Format batch response to ensure proper line breaks and spacing.
     * Converts markdown headers and ensures sections are on separate lines.
     */
    private String formatBatchResponse(String response) {
        if (response == null || response.isEmpty()) {
            return response;
        }
        
        // Replace markdown headers with newlines before them
        String formatted = response
            .replaceAll("(###+\\s)", "\n\n$1")  // Add spacing before markdown headers
            .replaceAll("(\\*\\*[^*]+\\*\\*)", "\n$1")  // Add newline before bold text (section titles)
            .replaceAll("(\\n\\s*\\n\\s*\\n+)", "\n\n")  // Normalize multiple newlines to double
            .replaceAll("(\\n)(-\\s)", "$1\n$2")  // Ensure bullet points are on new lines
            .replaceAll("(\\n)(\\d+\\.\\s)", "$1\n$2");  // Ensure numbered lists are on new lines
        
        // Ensure proper spacing between major sections
        formatted = formatted.replaceAll("(###\\s+[^#]+)", "\n\n$1\n");
        
        // Clean up any excessive whitespace but preserve intentional spacing
        formatted = formatted.replaceAll(" {3,}", "  ");  // Replace 3+ spaces with 2
        
        // Ensure the response ends with proper spacing
        if (!formatted.endsWith("\n\n")) {
            formatted += "\n";
        }
        
        return formatted.trim();
    }
    
    /**
     * Process batch of related endpoints (hybrid output: batch summary).
     * Called by EndpointBatchManager when a batch is ready.
     */
    private void processBatch(EndpointBatchManager.Batch batch) {
        if (batch.endpoints.isEmpty() || !llmClient.hasApiKey()) return;
        
        try {
            // Log batch formation (thread-safe, printOutput is safe from any thread)
            StringBuilder batchInfo = new StringBuilder();
            batchInfo.append("AI Pentest [Batch Formed] ").append(batch.commonVulnerability)
                     .append(" - ").append(batch.endpoints.size()).append(" endpoints:\n");
            for (int i = 0; i < batch.endpoints.size(); i++) {
                EndpointBatchManager.EndpointEntry entry = batch.endpoints.get(i);
                String method = entry.requestInfo.getMethod();
                String path = entry.requestInfo.getUrl().getPath();
                batchInfo.append(String.format("  %d. %s %s\n", i + 1, method, path));
            }
            callbacks.printOutput(batchInfo.toString());
            logToLivePanel(batchInfo.toString().trim(), "batch");
            
            // Build batch prompt with ALL evidence from all endpoints
            List<PromptBuilder.PTTNode> batchNodes = new ArrayList<>();
            List<ai.pentest.ptt.PTTNode> allPTTNodes = new ArrayList<>();
            
            for (EndpointBatchManager.EndpointEntry entry : batch.endpoints) {
                String summary = RequestFingerprint.buildCompactSummary(helpers, entry.messageInfo);
                PromptBuilder.PTTNode node = promptBuilder.buildPTTNode(entry.requestInfo, summary);
                batchNodes.add(node);
                allPTTNodes.addAll(entry.pttNodes);
            }
            
            // Build batch prompt (includes all evidence, even low scores)
            String batchPrompt = promptBuilder.buildBatchPrompt(batchNodes, batch.commonVulnerability);
            
            // Add all PTT evidence to batch prompt
            StringBuilder evidenceSection = new StringBuilder();
            evidenceSection.append("\nPTT Evidence across batch (all scores included):\n");
            for (ai.pentest.ptt.PTTNode n : allPTTNodes) {
                StringBuilder evidenceStr = new StringBuilder();
                if (!n.getEvidence().isEmpty()) {
                    evidenceStr.append(" evidence:[");
                    for (int i = 0; i < n.getEvidence().size() && i < 3; i++) {
                        if (i > 0) evidenceStr.append(", ");
                        evidenceStr.append(n.getEvidence().get(i).replace('\n', ' ').trim());
                    }
                    evidenceStr.append("]");
                }
                evidenceSection.append("- ").append(n.getTitle())
                    .append(":score=").append(String.format(java.util.Locale.ROOT, "%.2f", n.getScore()))
                    .append(evidenceStr.toString()).append("\n");
            }
            batchPrompt += evidenceSection.toString();
            
            // Mask PII
            String maskedPrompt = piiMasker.mask(batchPrompt);
            if (llmPromptLogger != null) {
                llmPromptLogger.logPrompt(
                        "Batch analysis: " + batch.commonVulnerability,
                        "Batch",
                        "endpoints=" + batch.endpoints.size(),
                        maskedPrompt
                );
            }
            
            // Log that batch is being sent to LLM (thread-safe)
            callbacks.printOutput(String.format(
                "AI Pentest [Processing Batch] Sending %d endpoints (%s) to LLM for analysis...",
                batch.endpoints.size(), batch.commonVulnerability
            ));
            logToLivePanel(String.format("[Processing Batch] %d endpoints (%s)",
                    batch.endpoints.size(), batch.commonVulnerability), "batch");
            
            // Process batch asynchronously to avoid blocking
            llmClient.completeAsync(maskedPrompt, 800).thenAccept(response -> {
                // Execute UI updates on EDT thread
                SwingUtilities.invokeLater(() -> {
                    if (response != null) {
                        String maskedResponse = piiMasker.mask(response);
                        
                        // Format response to preserve line breaks and add spacing
                        String formattedResponse = formatBatchResponse(maskedResponse);
                        
                        // Batch summary output with separator
                        String separator = "\n" + "=".repeat(80) + "\n";
                        callbacks.printOutput(separator + 
                            "AI Pentest [Batch Summary] - " + 
                            batch.commonVulnerability + " (" + batch.endpoints.size() + " endpoints):\n\n" + 
                            formattedResponse + "\n" + separator);
                        logToLivePanel(String.format("[Batch Summary] %s (%d endpoints)\n\n%s\n",
                                batch.commonVulnerability, batch.endpoints.size(), formattedResponse), "llm");
                        
                        // Log to file
                        if (llmOutputLogger != null) {
                            llmOutputLogger.logBatchSummary(
                                batch.commonVulnerability,
                                batch.endpoints.size(),
                                formattedResponse
                            );
                        }
                        
                        // Create issues for each endpoint in batch
                        for (EndpointBatchManager.EndpointEntry entry : batch.endpoints) {
                            PromptBuilder.PTTNode node = promptBuilder.buildPTTNode(
                                entry.requestInfo, 
                                RequestFingerprint.buildCompactSummary(helpers, entry.messageInfo)
                            );
                            Issue.TentativeAssessment assessment = Issue.evaluateTentative(maskedResponse, node);
                            reportTentativeIssue(entry.messageInfo, assessment);
                        }
                        
                        auditLogger.logEvent("batch_analysis", batch.commonVulnerability, 
                            "endpoints=" + batch.endpoints.size(), maskedResponse);
                        
                        // Mark as processed
                        for (EndpointBatchManager.EndpointEntry entry : batch.endpoints) {
                            batchManager.incrementProcessed();
                        }
                    } else {
                        callbacks.printOutput("AI Pentest [Batch Summary]: LLM returned null response for " + 
                            batch.commonVulnerability + " (" + batch.endpoints.size() + " endpoints)");
                        logToLivePanel(String.format("[Batch Summary] %s (%d endpoints): LLM returned null response",
                                batch.commonVulnerability, batch.endpoints.size()), "error");
                    }
                });
            }).exceptionally(ex -> {
                // Handle errors and display feedback
                SwingUtilities.invokeLater(() -> {
                    callbacks.printError("AI Pentest [Batch Summary] error: " + ex.getMessage());
                    if (ex.getCause() != null) {
                        callbacks.printError("Caused by: " + ex.getCause().getMessage());
                    }
                    StringBuilder errorMsg = new StringBuilder();
                    errorMsg.append("[Batch Error] ").append(ex.getMessage());
                    if (ex.getCause() != null) {
                        errorMsg.append(" | cause: ").append(ex.getCause().getMessage());
                    }
                    logToLivePanel(errorMsg.toString(), "error");
                    // Log error to file
                    if (llmOutputLogger != null) {
                        llmOutputLogger.logError("Batch Summary", errorMsg.toString());
                    }
                });
                return null;
            });
        } catch (Exception e) {
            callbacks.printError("Error processing batch: " + e.getMessage());
            logToLivePanel("[Batch Error] " + e.getMessage(), "error");
        }
    }

    private void reportTentativeIssue(IHttpRequestResponse base, Issue.TentativeAssessment assessment) {
        if (assessment == null || base == null) {
            return;
        }

        String evidence = assessment.evidence == null ? "" : assessment.evidence;
        String preview = evidence.length() > 240 ? evidence.substring(0, 240) + "..." : evidence;
        if (memoryManager != null) {
            memoryManager.recordFinding(assessment.title, preview);
        }
        if (memoryPanel != null) {
            SwingUtilities.invokeLater(memoryPanel::refreshFindings);
        }

        if (supportsScanIssues) {
            try {
                callbacks.addScanIssue(Issue.buildTentativeIssue(callbacks, base, assessment));
                return;
            } catch (Throwable t) {
                supportsScanIssues = false;
                callbacks.printError("AI Pentest: Scanner issue reporting unavailable (" + t.getMessage() + "). Falling back to console logging.");
            }
        }

        String message = "[Tentative Finding] " + assessment.title + "\n" + preview;
        callbacks.printOutput(message);
        logToLivePanel(message, "llm");
        if (auditLogger != null) {
            auditLogger.logEvent("tentative_finding", assessment.title, "preview", preview);
        }
    }
}


